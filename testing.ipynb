{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bpn8Rs4tKYj_"
      },
      "source": [
        "# Model testing for ViT\n",
        "\n",
        "This notebook will be structered in two sections\n",
        "\n",
        "**section 1:** the plaintext model testing first the tensorboard will be checked then the accuracy report\n",
        "\n",
        "**section 2:** the encrypted images first the data will be tested on the validation set to check the accuracy of the model then the test set will be used for checking the similarity metricies which are accuracy precision recall false positive rate (FPR)  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FogVLTCUL2V_"
      },
      "source": [
        "## Section 1 Plaintext model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GNkuSF5nL5vA"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")\n",
        "%load_ext tensorboard\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0NGTJLpmOhHC"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "try:\n",
        "    import timm\n",
        "\n",
        "except ModuleNotFoundError:\n",
        "    !pip install timm\n",
        "    import timm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZQW_Dj6OURej"
      },
      "outputs": [],
      "source": [
        "!mkdir data\n",
        "!unzip /content/drive/MyDrive/Bustati/potato.zip -d data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FEBDTeYMzrcI"
      },
      "source": [
        "### 1.1 ViT Plaintext"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "df7QkzTfL_cS"
      },
      "outputs": [],
      "source": [
        "%tensorboard --logdir drive/MyDrive/Bustati/Bustati/runs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WLFnhFEsT97-"
      },
      "outputs": [],
      "source": [
        "import timm\n",
        "import torch\n",
        "from pathlib import Path\n",
        "from torch import nn\n",
        "from torchvision import transforms\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision.datasets import ImageFolder\n",
        "\n",
        "# Create an instance of the model\n",
        "model = timm.create_model(\"vit_base_patch16_224\", num_classes=3)\n",
        "\n",
        "# Load the state_dict\n",
        "checkpoint = torch.load(\"/content/drive/MyDrive/Bustati/Bustati/best_model.pth\")\n",
        "\n",
        "# Extract relevant information\n",
        "model.load_state_dict(checkpoint['model_state_dict'])\n",
        "epoch = checkpoint['epoch']\n",
        "optimizer_state_dict = checkpoint['optimizer_state_dict']\n",
        "\n",
        "# The model is now loaded with the trained weights\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WMEITOL_QAp2"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "data_cfg = timm.data.resolve_data_config(model.pretrained_cfg)\n",
        "transform = timm.data.create_transform(**data_cfg)\n",
        "\n",
        "data_path = Path(\"/content/data\")\n",
        "test_path = data_path/\"test\"\n",
        "\n",
        "test_data = ImageFolder(\n",
        "    test_path,\n",
        "    transform=transform,\n",
        ")\n",
        "data_loader = DataLoader(\n",
        "    test_data,\n",
        "    shuffle=False,\n",
        "    num_workers=int(os.cpu_count()),\n",
        "    batch_size=32\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Tvm5Jw45WsHP"
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = model.to(device)\n",
        "model.eval()\n",
        "y_true = []\n",
        "y_hat = []\n",
        "with torch.inference_mode():\n",
        "    for X,y in data_loader:\n",
        "        X,y=X.to(device),y.to(device)\n",
        "        y_preds = model(X).argmax(axis=1)\n",
        "        y_true.append(y)\n",
        "        y_hat.append(y_preds)\n",
        "    y_true=torch.cat(y_true,0)\n",
        "    y_hat=torch.cat(y_hat,0)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gfgqAH6eZHgI"
      },
      "outputs": [],
      "source": [
        "if y_true.device != \"cpu\":\n",
        "    y_true = y_true.cpu().numpy()\n",
        "    y_hat = y_hat.cpu().numpy()\n",
        "else:\n",
        "    y_true = y_true.numpy()\n",
        "    y_hat = y_hat.numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L380DbnnZQR1"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(y_true,y_hat))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ctlzKF0y0iNA"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from sklearn.metrics import confusion_matrix,ConfusionMatrixDisplay\n",
        "cf = confusion_matrix(y_true,y_hat)\n",
        "disp = ConfusionMatrixDisplay(cf,display_labels=np.array(test_data.classes))\n",
        "disp.plot()\n",
        "plt.title(\"ViT Plaintext \")\n",
        "plt.savefig(\"ViT Plaintext conf-mat.svg\",format=\"svg\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JrXAQkw4cGJh"
      },
      "source": [
        "**The results are satisfying**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cXV3YHI2zzOM"
      },
      "source": [
        "### 1.2 VGG-16"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iSD5sYuF0yhF"
      },
      "outputs": [],
      "source": [
        "%tensorboard --logdir drive/MyDrive/Bustati/Bustati/vgg_plaintext"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZPlRfoni0tGY"
      },
      "outputs": [],
      "source": [
        "import timm\n",
        "import torch\n",
        "from pathlib import Path\n",
        "from torch import nn\n",
        "from torchvision import transforms\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision.datasets import ImageFolder\n",
        "\n",
        "# Create an instance of the model\n",
        "model = timm.create_model(\"vgg16\", num_classes=3)\n",
        "\n",
        "# Load the state_dict\n",
        "checkpoint = torch.load(\"/content/drive/MyDrive/Bustati/Bustati/vgg16_plaintext.pth\")\n",
        "\n",
        "# Extract relevant information\n",
        "model.load_state_dict(checkpoint['model_state_dict'])\n",
        "epoch = checkpoint['epoch']\n",
        "optimizer_state_dict = checkpoint['optimizer_state_dict']\n",
        "\n",
        "# The model is now loaded with the trained weights\n",
        "\n",
        "import os\n",
        "data_cfg = timm.data.resolve_data_config(model.pretrained_cfg)\n",
        "transform = timm.data.create_transform(**data_cfg)\n",
        "\n",
        "data_path = Path(\"/content/data\")\n",
        "test_path = data_path/\"test\"\n",
        "\n",
        "test_data = ImageFolder(\n",
        "    test_path,\n",
        "    transform=transform,\n",
        ")\n",
        "data_loader = DataLoader(\n",
        "    test_data,\n",
        "    shuffle=False,\n",
        "    num_workers=int(os.cpu_count()),\n",
        "    batch_size=32\n",
        ")\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = model.to(device)\n",
        "model.eval()\n",
        "y_true = []\n",
        "y_hat = []\n",
        "with torch.inference_mode():\n",
        "    for X,y in data_loader:\n",
        "        X,y=X.to(device),y.to(device)\n",
        "        y_preds = model(X).argmax(axis=1)\n",
        "        y_true.append(y)\n",
        "        y_hat.append(y_preds)\n",
        "    y_true=torch.cat(y_true,0)\n",
        "    y_hat=torch.cat(y_hat,0)\n",
        "\n",
        "if y_true.device != \"cpu\":\n",
        "    y_true = y_true.cpu().numpy()\n",
        "    y_hat = y_hat.cpu().numpy()\n",
        "else:\n",
        "    y_true = y_true.numpy()\n",
        "    y_hat = y_hat.numpy()\n",
        "\n",
        "\n",
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(y_true,y_hat))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w2I6tBGQ1U3v"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import confusion_matrix,ConfusionMatrixDisplay\n",
        "cf = confusion_matrix(y_true,y_hat)\n",
        "disp = ConfusionMatrixDisplay(cf,display_labels=np.array(test_data.classes))\n",
        "disp.plot()\n",
        "plt.title(\"VGG-16 Plaintext \")\n",
        "plt.savefig(\"VGG-16 Plaintext conf-mat.svg\",format=\"svg\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rdgq2UoIcEjf"
      },
      "source": [
        "## Section 2 encrypted models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RNNuHDXae7Mi"
      },
      "source": [
        "### 2.1 ViT model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LEZBDvZhZ0Aa"
      },
      "outputs": [],
      "source": [
        "%tensorboard --logdir /content/drive/MyDrive/Bustati/Bustati/encrypted_run"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7hSV7StLd8qY"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "import numpy as np\n",
        "import random\n",
        "import torch\n",
        "from torchvision import transforms\n",
        "\n",
        "class ImageEncryption:\n",
        "    \"\"\"\n",
        "    Class for image encryption using a combination of intra-block texture encryption\n",
        "    and color encryption.\n",
        "\n",
        "    Args:\n",
        "        m (int): The number of subblocks in each dimension.\n",
        "\n",
        "    Attributes:\n",
        "        m (int): The number of subblocks in each dimension.\n",
        "\n",
        "    Methods:\n",
        "        image_encryption(image_path):\n",
        "            Encrypts an image using intra-block texture encryption and color encryption.\n",
        "\n",
        "        intrablock_texture_encryption(subblock):\n",
        "            Encrypts a subblock using intra-block texture encryption.\n",
        "\n",
        "        color_encryption(subblock, i):\n",
        "            Encrypts a subblock using color encryption.\n",
        "    \"\"\"\n",
        "    def __init__(self, m):\n",
        "        \"\"\"\n",
        "        Initializes the ImageEncryption object.\n",
        "\n",
        "        Args:\n",
        "            m (int): The number of subblocks in each dimension.\n",
        "        \"\"\"\n",
        "        self.m = m\n",
        "\n",
        "    def image_encryption(self, image_path):\n",
        "        \"\"\"\n",
        "        Encrypts an image using intra-block texture encryption and color encryption.\n",
        "\n",
        "        Args:\n",
        "            image_path (str): The path to the input image file.\n",
        "\n",
        "        Returns:\n",
        "            tuple: A tuple containing the encrypted image, image subkeys, and block keys.\n",
        "        \"\"\"\n",
        "        # Load image using cv2.imread\n",
        "        open_cv_image = np.array(image_path)\n",
        "        # Convert RGB to BGR\n",
        "        open_cv_image = open_cv_image[:, :, ::-1].copy()\n",
        "        img = cv2.resize(open_cv_image,(224,224))\n",
        "        height, width = img.shape[:2]  # Get height and width using img.shape\n",
        "        w_subblock = width // self.m\n",
        "        h_subblock = height // self.m\n",
        "\n",
        "        image_subblocks = []\n",
        "        for i in range(self.m):\n",
        "            for j in range(self.m):\n",
        "                x1 = i * w_subblock\n",
        "                y1 = j * h_subblock\n",
        "                x2 = x1 + w_subblock\n",
        "                y2 = y1 + h_subblock\n",
        "                subblock = img[y1:y2, x1:x2]  # Crop using array slicing\n",
        "                image_subblocks.append(subblock)\n",
        "\n",
        "        encrypted_image_subblocks = []\n",
        "        key_image_subblocks = []\n",
        "        for subblock in image_subblocks:\n",
        "            encrypted_subblock, subK = self.intrablock_texture_encryption(np.array(subblock))\n",
        "            encrypted_image_subblocks.append(encrypted_subblock)\n",
        "            key_image_subblocks.append(subK)\n",
        "\n",
        "        img_sub_key = np.empty(len(encrypted_image_subblocks))\n",
        "        for i in range(len(encrypted_image_subblocks)-1, -1, -1):\n",
        "            n = random.randint(0, i)\n",
        "            encrypted_image_subblocks[i], encrypted_image_subblocks[n] = encrypted_image_subblocks[n], encrypted_image_subblocks[i]\n",
        "            key_image_subblocks[i], key_image_subblocks[n] = key_image_subblocks[n], key_image_subblocks[i]\n",
        "            img_sub_key[i] = n\n",
        "\n",
        "        for i in range(len(encrypted_image_subblocks)):\n",
        "            encrypted_image_subblocks[i] = self.color_encryption(encrypted_image_subblocks[i], i)\n",
        "\n",
        "        original_image = np.zeros((height, width, 3))\n",
        "        for i in range(self.m):\n",
        "            for j in range(self.m):\n",
        "                x1 = i * w_subblock\n",
        "                y1 = j * h_subblock\n",
        "                x2 = x1 + w_subblock\n",
        "                y2 = y1 + h_subblock\n",
        "                original_image[y1:y2, x1:x2] = encrypted_image_subblocks[i * self.m + j]\n",
        "        encrypted_image_subblocks = original_image\n",
        "\n",
        "        return encrypted_image_subblocks.astype(np.uint8), img_sub_key, key_image_subblocks\n",
        "\n",
        "    def intrablock_texture_encryption(self, subblock):\n",
        "        \"\"\"\n",
        "        Encrypts a subblock using intra-block texture encryption.\n",
        "\n",
        "        Args:\n",
        "            subblock (numpy.ndarray): The input subblock to be encrypted.\n",
        "\n",
        "        Returns:\n",
        "            tuple: A tuple containing the encrypted subblock and a dictionary of subkeys.\n",
        "        \"\"\"\n",
        "        lr, lg, lb = cv2.split(subblock)\n",
        "\n",
        "        # Flatten the color channels\n",
        "        lr_flat = lr.flatten()\n",
        "        lg_flat = lg.flatten()\n",
        "        lb_flat = lb.flatten()\n",
        "\n",
        "        # Initialize empty key lists for each channel\n",
        "        sub_img_r_key = np.empty(lr_flat.shape)\n",
        "        sub_img_g_key = np.empty(lr_flat.shape)\n",
        "        sub_img_b_key = np.empty(lr_flat.shape)\n",
        "\n",
        "        # Random shuffling with key generation\n",
        "        for i in range(len(lb_flat)-1, -1, -1):\n",
        "            r = random.randint(0, i)\n",
        "            sub_img_r_key[i] = r\n",
        "            g = random.randint(0, i)\n",
        "            sub_img_g_key[i] = g\n",
        "            b = random.randint(0, i)\n",
        "            sub_img_b_key[i] = b\n",
        "\n",
        "            lr_flat[i], lr_flat[r] = lr_flat[r], lr_flat[i]\n",
        "            lg_flat[i], lg_flat[g] = lg_flat[g], lg_flat[i]\n",
        "            lb_flat[i], lb_flat[b] = lb_flat[b], lb_flat[i]\n",
        "\n",
        "        # Reshape flattened arrays to original shape\n",
        "        lr_flat = lr_flat.reshape(lr.shape)\n",
        "        lg_flat = lg_flat.reshape(lg.shape)\n",
        "        lb_flat = lb_flat.reshape(lb.shape)\n",
        "\n",
        "        # Merge that to become an RGB image\n",
        "        encrypted_subblock = cv2.merge((lr_flat, lg_flat, lb_flat))\n",
        "\n",
        "        # Create subK dictionary to store keys\n",
        "        subK = {\n",
        "            \"sub_img_r_key\": sub_img_r_key,\n",
        "            \"sub_img_g_key\": sub_img_g_key,\n",
        "            \"sub_img_b_key\": sub_img_b_key\n",
        "        }\n",
        "        return encrypted_subblock, subK\n",
        "\n",
        "    def color_encryption(self, subblock, i):\n",
        "        \"\"\"\n",
        "        Encrypts a subblock using color encryption.\n",
        "\n",
        "        Args:\n",
        "            subblock (numpy.ndarray): The input subblock to be encrypted.\n",
        "            i (int): An index used in the encryption process.\n",
        "\n",
        "        Returns:\n",
        "            numpy.ndarray: The encrypted subblock.\n",
        "        \"\"\"\n",
        "        er, eg, eb = cv2.split(subblock)\n",
        "        er_flat = er.flatten()\n",
        "        eg_flat = eg.flatten()\n",
        "        eb_flat = eb.flatten()\n",
        "\n",
        "        eb_flat_ = np.asarray([(e + i / self.m * 256 / self.m) % 256 for e in er_flat]).astype(int)\n",
        "        er_flat_ = np.asarray([(e + (i % self.m) * 256 / self.m) % 256 for e in eg_flat]).astype(int)\n",
        "        eg_flat_ = np.asarray([(e + (i / self.m + i % self.m) * 128 / self.m) % 256 for e in eb_flat]).astype(int)\n",
        "\n",
        "        er_flat_ = er_flat_.reshape(er.shape)\n",
        "        eg_flat_ = eg_flat_.reshape(eg.shape)\n",
        "        eb_flat_ = eb_flat_.reshape(eb.shape)\n",
        "\n",
        "        encrypted_subblock = cv2.merge((er_flat_, eg_flat_, eb_flat_))\n",
        "\n",
        "        return encrypted_subblock.astype(np.uint8)\n",
        "\n",
        "\n",
        "class ImageEncryptionTransform(object):\n",
        "    def __init__(self, m):\n",
        "        super().__init__()\n",
        "        self.m = m\n",
        "        self.image_encryption = ImageEncryption(m)  # Create an instance of your class\n",
        "\n",
        "    def __call__(self, img):\n",
        "        # Process the image using the image_encryption object\n",
        "        encrypted_img, _, _ = self.image_encryption.image_encryption(img)\n",
        "        encrypted_img = encrypted_img.astype(np.float32)\n",
        "        encrypted_img/=255.0\n",
        "        encrypted_img = torch.from_numpy(encrypted_img)\n",
        "        return encrypted_img.permute(2,0,1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TWeQfdvccCdD"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import timm\n",
        "import torch\n",
        "from pathlib import Path\n",
        "from torch import nn\n",
        "from torchvision import transforms\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision.datasets import ImageFolder\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "def set_seeds(seed=42):\n",
        "    torch.manual_seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "\n",
        "# Create an instance of the model\n",
        "model = timm.create_model(\"vit_base_patch16_224\", num_classes=3)\n",
        "\n",
        "# Load the state_dict\n",
        "checkpoint = torch.load(\"/content/drive/MyDrive/Bustati/Bustati/best_model_encrypted.pth\")\n",
        "\n",
        "# Extract relevant information\n",
        "model.load_state_dict(checkpoint['model_state_dict'])\n",
        "epoch = checkpoint['epoch']\n",
        "optimizer_state_dict = checkpoint['optimizer_state_dict']\n",
        "\n",
        "# The model is now loaded with the trained weights\n",
        "transform = transforms.Compose([\n",
        "    ImageEncryptionTransform(m=8),  # Apply encryption with desired number of subblocks\n",
        "])\n",
        "\n",
        "data_path = Path(\"/content/data\")\n",
        "test_path = data_path/\"test\"\n",
        "\n",
        "test_data = ImageFolder(\n",
        "    test_path,\n",
        "    transform=transform,\n",
        ")\n",
        "data_loader = DataLoader(\n",
        "    test_data,\n",
        "    shuffle=False,\n",
        "    num_workers=int(os.cpu_count()),\n",
        "    batch_size=32\n",
        ")\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = model.to(device)\n",
        "model.eval()\n",
        "y_true = []\n",
        "y_hat = []\n",
        "with torch.inference_mode():\n",
        "    for X,y in data_loader:\n",
        "        X,y=X.to(device),y.to(device)\n",
        "        y_logits = model(X).softmax(axis=1)\n",
        "        y_preds = y_logits.argmax(axis=1)\n",
        "        y_true.append(y)\n",
        "        y_hat.append(y_preds)\n",
        "    y_true=torch.cat(y_true,0)\n",
        "    y_hat=torch.cat(y_hat,0)\n",
        "\n",
        "if y_true.device != \"cpu\":\n",
        "    y_true = y_true.cpu().numpy()\n",
        "    y_hat = y_hat.cpu().numpy()\n",
        "else:\n",
        "    y_true = y_true.numpy()\n",
        "    y_hat = y_hat.numpy()\n",
        "\n",
        "\n",
        "print(classification_report(y_true,y_hat))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2qar8-kkeD7M"
      },
      "outputs": [],
      "source": [
        "print(classification_report(y_true,y_hat))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uQZBtMhkfNaS"
      },
      "outputs": [],
      "source": [
        "accuracy_score(y_true,y_hat)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SffYwGqik1zg"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import confusion_matrix,ConfusionMatrixDisplay\n",
        "cf = confusion_matrix(y_true,y_hat)\n",
        "disp = ConfusionMatrixDisplay(cf,display_labels=np.array(test_data.classes))\n",
        "disp.plot()\n",
        "plt.title(\"ViT 8 Blocks \")\n",
        "plt.savefig(\"ViT 8 Blocks conf-mat.svg\",format=\"svg\")\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LRu86HObe4Hz"
      },
      "source": [
        "### 2.2 VGG-16"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FgAbdQy8fB37"
      },
      "outputs": [],
      "source": [
        "%tensorboard --logdir /content/drive/MyDrive/Bustati/Bustati/encrypted_vgg"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lDREYLcbfvVv"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import timm\n",
        "import torch\n",
        "from pathlib import Path\n",
        "from torch import nn\n",
        "from torchvision import transforms\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision.datasets import ImageFolder\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "def set_seeds(seed=42):\n",
        "    torch.manual_seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "\n",
        "# Create an instance of the model\n",
        "model = timm.create_model(\"vgg16\", num_classes=3)\n",
        "\n",
        "# Load the state_dict\n",
        "checkpoint = torch.load(\"/content/drive/MyDrive/Bustati/Bustati/best_vgg.pth\")\n",
        "\n",
        "# Extract relevant information\n",
        "model.load_state_dict(checkpoint['model_state_dict'])\n",
        "epoch = checkpoint['epoch']\n",
        "optimizer_state_dict = checkpoint['optimizer_state_dict']\n",
        "\n",
        "# The model is now loaded with the trained weights\n",
        "transform = transforms.Compose([\n",
        "    ImageEncryptionTransform(m=8),  # Apply encryption with desired number of subblocks\n",
        "])\n",
        "\n",
        "data_path = Path(\"/content/data\")\n",
        "test_path = data_path/\"test\"\n",
        "\n",
        "test_data = ImageFolder(\n",
        "    test_path,\n",
        "    transform=transform,\n",
        ")\n",
        "data_loader = DataLoader(\n",
        "    test_data,\n",
        "    shuffle=False,\n",
        "    num_workers=int(os.cpu_count()),\n",
        "    batch_size=32\n",
        ")\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = model.to(device)\n",
        "model.eval()\n",
        "y_true = []\n",
        "y_hat = []\n",
        "with torch.inference_mode():\n",
        "    for X,y in data_loader:\n",
        "        X,y=X.to(device),y.to(device)\n",
        "        y_logits = model(X).softmax(axis=1)\n",
        "        y_preds = y_logits.argmax(axis=1)\n",
        "        y_true.append(y)\n",
        "        y_hat.append(y_preds)\n",
        "    y_true=torch.cat(y_true,0)\n",
        "    y_hat=torch.cat(y_hat,0)\n",
        "\n",
        "if y_true.device != \"cpu\":\n",
        "    y_true = y_true.cpu().numpy()\n",
        "    y_hat = y_hat.cpu().numpy()\n",
        "else:\n",
        "    y_true = y_true.numpy()\n",
        "    y_hat = y_hat.numpy()\n",
        "\n",
        "\n",
        "print(classification_report(y_true,y_hat))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JmPPThKbgCtR"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import confusion_matrix,ConfusionMatrixDisplay\n",
        "cf = confusion_matrix(y_true,y_hat)\n",
        "disp = ConfusionMatrixDisplay(cf,display_labels=np.array(test_data.classes))\n",
        "disp.plot()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3MaVrYAk47VU"
      },
      "source": [
        "## Section 3 Encrypted domain with one block"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GCc9BXM24__3"
      },
      "source": [
        "### 3.1 ViT model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-ZwgUtkA5DJZ"
      },
      "outputs": [],
      "source": [
        "%tensorboard --logdir /content/drive/MyDrive/Bustati/Bustati/one_block_vit"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XFwmLqgT5KPu"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import timm\n",
        "import torch\n",
        "from pathlib import Path\n",
        "from torch import nn\n",
        "from torchvision import transforms\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision.datasets import ImageFolder\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "def set_seeds(seed=42):\n",
        "    torch.manual_seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "\n",
        "# Create an instance of the model\n",
        "model = timm.create_model(\"vit_base_patch16_224\", num_classes=3)\n",
        "\n",
        "# Load the state_dict\n",
        "checkpoint = torch.load(\"/content/drive/MyDrive/Bustati/Bustati/one_block_vit.pth\")\n",
        "\n",
        "# Extract relevant information\n",
        "model.load_state_dict(checkpoint['model_state_dict'])\n",
        "epoch = checkpoint['epoch']\n",
        "optimizer_state_dict = checkpoint['optimizer_state_dict']\n",
        "\n",
        "# The model is now loaded with the trained weights\n",
        "transform = transforms.Compose([\n",
        "    ImageEncryptionTransform(m=1),  # Apply encryption with desired number of subblocks\n",
        "])\n",
        "\n",
        "data_path = Path(\"/content/data\")\n",
        "test_path = data_path/\"test\"\n",
        "\n",
        "test_data = ImageFolder(\n",
        "    test_path,\n",
        "    transform=transform,\n",
        ")\n",
        "data_loader = DataLoader(\n",
        "    test_data,\n",
        "    shuffle=False,\n",
        "    num_workers=int(os.cpu_count()),\n",
        "    batch_size=32\n",
        ")\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = model.to(device)\n",
        "model.eval()\n",
        "y_true = []\n",
        "y_hat = []\n",
        "with torch.inference_mode():\n",
        "    for X,y in data_loader:\n",
        "        X,y=X.to(device),y.to(device)\n",
        "        y_logits = model(X).softmax(axis=1)\n",
        "        y_preds = y_logits.argmax(axis=1)\n",
        "        y_true.append(y)\n",
        "        y_hat.append(y_preds)\n",
        "    y_true=torch.cat(y_true,0)\n",
        "    y_hat=torch.cat(y_hat,0)\n",
        "\n",
        "if y_true.device != \"cpu\":\n",
        "    y_true = y_true.cpu().numpy()\n",
        "    y_hat = y_hat.cpu().numpy()\n",
        "else:\n",
        "    y_true = y_true.numpy()\n",
        "    y_hat = y_hat.numpy()\n",
        "\n",
        "\n",
        "print(classification_report(y_true,y_hat))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pU1w2Dpa5Pm5"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import confusion_matrix,ConfusionMatrixDisplay\n",
        "cf = confusion_matrix(y_true,y_hat)\n",
        "disp = ConfusionMatrixDisplay(cf,display_labels=np.array(test_data.classes))\n",
        "disp.plot()\n",
        "plt.title(\"ViT 1 Block \")\n",
        "plt.savefig(\"ViT 1 Block conf-mat.svg\",format=\"svg\")\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kvPLQKe55QEP"
      },
      "source": [
        "### 3.2 VGG-16"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cg9XShYe5XXW"
      },
      "outputs": [],
      "source": [
        "%tensorboard --logdir /content/drive/MyDrive/Bustati/Bustati/one_block_vgg"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ddwcdy3Z5Sw-"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import timm\n",
        "import torch\n",
        "from pathlib import Path\n",
        "from torch import nn\n",
        "from torchvision import transforms\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision.datasets import ImageFolder\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "def set_seeds(seed=42):\n",
        "    torch.manual_seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "\n",
        "# Create an instance of the model\n",
        "model = timm.create_model(\"vgg16\", num_classes=3)\n",
        "\n",
        "# Load the state_dict\n",
        "checkpoint = torch.load(\"/content/drive/MyDrive/Bustati/Bustati/one_block_vgg.pth\")\n",
        "\n",
        "# Extract relevant information\n",
        "model.load_state_dict(checkpoint['model_state_dict'])\n",
        "epoch = checkpoint['epoch']\n",
        "optimizer_state_dict = checkpoint['optimizer_state_dict']\n",
        "\n",
        "# The model is now loaded with the trained weights\n",
        "transform = transforms.Compose([\n",
        "    ImageEncryptionTransform(m=1),  # Apply encryption with desired number of subblocks\n",
        "])\n",
        "\n",
        "data_path = Path(\"/content/data\")\n",
        "test_path = data_path/\"test\"\n",
        "\n",
        "test_data = ImageFolder(\n",
        "    test_path,\n",
        "    transform=transform,\n",
        ")\n",
        "data_loader = DataLoader(\n",
        "    test_data,\n",
        "    shuffle=False,\n",
        "    num_workers=int(os.cpu_count()),\n",
        "    batch_size=32\n",
        ")\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = model.to(device)\n",
        "model.eval()\n",
        "y_true = []\n",
        "y_hat = []\n",
        "with torch.inference_mode():\n",
        "    for X,y in data_loader:\n",
        "        X,y=X.to(device),y.to(device)\n",
        "        y_logits = model(X).softmax(axis=1)\n",
        "        y_preds = y_logits.argmax(axis=1)\n",
        "        y_true.append(y)\n",
        "        y_hat.append(y_preds)\n",
        "    y_true=torch.cat(y_true,0)\n",
        "    y_hat=torch.cat(y_hat,0)\n",
        "\n",
        "if y_true.device != \"cpu\":\n",
        "    y_true = y_true.cpu().numpy()\n",
        "    y_hat = y_hat.cpu().numpy()\n",
        "else:\n",
        "    y_true = y_true.numpy()\n",
        "    y_hat = y_hat.numpy()\n",
        "\n",
        "\n",
        "print(classification_report(y_true,y_hat))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R_Y7kz-i5U5G"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import confusion_matrix,ConfusionMatrixDisplay\n",
        "cf = confusion_matrix(y_true,y_hat)\n",
        "disp = ConfusionMatrixDisplay(cf,display_labels=np.array(test_data.classes))\n",
        "disp.plot()\n",
        "plt.title(\"VGG-16 1 Block \")\n",
        "plt.savefig(\"VGG-16 1 Block conf-mat.svg\",format=\"svg\")\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n8ILTUXw5tQX"
      },
      "source": [
        "## Section 4 ONN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3q4bTyI850Dl"
      },
      "outputs": [],
      "source": [
        "%tensorboard --logdir /content/drive/MyDrive/Bustati/Bustati/onn_vgg"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        " !pip install git+https://github.com/junaidmalik09/fastonn.git\n",
        " !git clone https://github.com/junaidmalik09/fastonn.git"
      ],
      "metadata": {
        "id": "qirbC-7xWVPy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# get the files of VLPSO\n",
        "import sys\n",
        "from fastonn.osl import *\n",
        "from fastonn.utils import *\n",
        "from fastonn import OpNetwork,utils,OpTier,OpBlock,Trainer\n",
        "from fastonn.utils import get_dataset_with_folds,ONNDataset\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "sys.path.insert(0,'/content/fastonn')\n",
        "nodal = [mul,cubic,sine,expp,sinh,sinc2.apply,chirp]\n",
        "act = [tanh,lincut]\n",
        "pool = [summ]\n",
        "OPLIB = getOPLIB(nodal,pool,act)"
      ],
      "metadata": {
        "id": "OT44Z36qWZmK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import timm\n",
        "import torch\n",
        "from pathlib import Path\n",
        "from torch import nn\n",
        "from torchvision import transforms\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision.datasets import ImageFolder\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "def set_seeds(seed=42):\n",
        "    torch.manual_seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "\n",
        "# Create an instance of the model\n",
        "onnmodel = timm.create_model('vgg16',pretrained=True,num_classes=3)\n",
        "\n",
        "in_channels=3\n",
        "tier_sizes=[3,16,3]\n",
        "kernel_sizes=[21,3,16]\n",
        "operators=[[1],[3],[6]]\n",
        "sampling_factors=[2,-2,1]\n",
        "OPLIB=OPLIB\n",
        "pad=-1\n",
        "\n",
        "for i in range(len(tier_sizes)):\n",
        "  if i==0: onnmodel.add_module(str(i),OpTier(in_channels,tier_sizes[i],kernel_sizes[i],operators[i],OPLIB))\n",
        "  else: onnmodel.add_module(str(i),OpTier(tier_sizes[i-1],tier_sizes[i],kernel_sizes[i],operators[i],OPLIB))\n",
        "\n",
        "onnmodel.add_module('flatten final', nn.Flatten())\n",
        "onnmodel.add_module('classifier final', nn.Linear(tier_sizes[-1] * 224*224, 3))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Load the state_dict\n",
        "checkpoint = torch.load(\"/content/drive/MyDrive/Bustati/Bustati/onn_vgg.pth\")\n",
        "\n",
        "# Extract relevant information\n",
        "onnmodel.load_state_dict(checkpoint['model_state_dict'])\n",
        "epoch = checkpoint['epoch']\n",
        "optimizer_state_dict = checkpoint['optimizer_state_dict']\n",
        "\n",
        "# The model is now loaded with the trained weights\n",
        "transform = transforms.Compose([\n",
        "    ImageEncryptionTransform(m=8),  # Apply encryption with desired number of subblocks\n",
        "])\n",
        "\n",
        "data_path = Path(\"/content/data\")\n",
        "test_path = data_path/\"test\"\n",
        "\n",
        "test_data = ImageFolder(\n",
        "    test_path,\n",
        "    transform=transform,\n",
        ")\n",
        "data_loader = DataLoader(\n",
        "    test_data,\n",
        "    shuffle=False,\n",
        "    num_workers=int(os.cpu_count()),\n",
        "    batch_size=32\n",
        ")\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "onnmodel.apply(reset_function_generic)\n",
        "onnmodel = onnmodel.to(device)\n",
        "onnmodel.eval()\n",
        "y_true = []\n",
        "y_hat = []\n",
        "with torch.inference_mode():\n",
        "    for X,y in data_loader:\n",
        "        X,y=X.to(device),y.to(device)\n",
        "        y_logits = onnmodel(X).softmax(axis=1)\n",
        "        y_preds = y_logits.argmax(axis=1)\n",
        "        y_true.append(y)\n",
        "        y_hat.append(y_preds)\n",
        "    y_true=torch.cat(y_true,0)\n",
        "    y_hat=torch.cat(y_hat,0)\n",
        "\n",
        "if y_true.device != \"cpu\":\n",
        "    y_true = y_true.cpu().numpy()\n",
        "    y_hat = y_hat.cpu().numpy()\n",
        "else:\n",
        "    y_true = y_true.numpy()\n",
        "    y_hat = y_hat.numpy()\n",
        "\n",
        "\n",
        "print(classification_report(y_true,y_hat))"
      ],
      "metadata": {
        "id": "vxMYz8nKV8uI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import confusion_matrix,ConfusionMatrixDisplay\n",
        "cf = confusion_matrix(y_true,y_hat)\n",
        "disp = ConfusionMatrixDisplay(cf,display_labels=np.array(test_data.classes))\n",
        "disp.plot()\n",
        "plt.title(\"VGG-16 with ONN \")\n",
        "plt.savefig(\"VGG-16 with ONN conf-mat.svg\",format=\"svg\")\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ATUEfXZUWEXR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "OIQqQ7QWdnsT"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}